# app.py â€” ë³´í—˜ ì•½ê´€ RAG ì±—ë´‡ (HTML UI + GPT-5 + Supabase pgvector, ëª¨ë°”ì¼ ëŒ€ì‘)
import os, json, time, typing as t, numpy as np, psycopg, pandas as pd, streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
import streamlit.components.v1 as components

# =========================
# ğŸ”§ í™˜ê²½ ë³€ìˆ˜
# =========================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
DB_HOST = os.getenv("DB_HOST") or st.secrets.get("DB_HOST")
DB_PORT = int(os.getenv("DB_PORT") or st.secrets.get("DB_PORT", 5432))
DB_NAME = os.getenv("DB_NAME") or st.secrets.get("DB_NAME")
DB_USER = os.getenv("DB_USER") or st.secrets.get("DB_USER")
DB_PASS = os.getenv("DB_PASS") or st.secrets.get("DB_PASS")

client = OpenAI(api_key=OPENAI_API_KEY)
model = ChatOpenAI(model="gpt-5", reasoning_effort="minimal", api_key=OPENAI_API_KEY)

# =========================
# ğŸ“¦ ì„¸ì…˜ ìƒíƒœ
# =========================
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
    ]

# =========================
# ğŸ“¦ DB ì—°ê²° í•¨ìˆ˜
# =========================
DB_CONN = {
    "host": DB_HOST,
    "port": DB_PORT,
    "dbname": DB_NAME,
    "user": DB_USER,
    "password": DB_PASS,
    "sslmode": "require",
    "connect_timeout": 10,
}

SEARCH_SQL = """
WITH q AS (SELECT %(vec)s::vector AS v)
SELECT
  pdf_filename,
  COALESCE((metadata_json->>'pdf_path'), pdf_path) AS pdf_path,
  page,
  text,
  (1 - (embedding <=> (SELECT v FROM q))) AS cosine_similarity
FROM public.terms_chunks
ORDER BY cosine_similarity DESC
LIMIT %(k)s;
"""

def to_vector_literal(vec):
    return "[" + ",".join(f"{x:.8f}" for x in vec) + "]"

def embed_text(text: str) -> list[float]:
    e = client.embeddings.create(model="text-embedding-3-small", input=text)
    v = np.array(e.data[0].embedding, dtype=np.float32)
    norm = np.linalg.norm(v)
    return (v / norm).tolist() if norm > 0 else v.tolist()

def fetch_topk_chunks(q_vec, k=5):
    vec_literal = to_vector_literal(q_vec)
    with psycopg.connect(**DB_CONN) as conn, conn.cursor() as cur:
        cur.execute(SEARCH_SQL, {"vec": vec_literal, "k": k})
        rows = cur.fetchall()
        cols = [d.name for d in cur.description]
    return pd.DataFrame(rows, columns=cols)

# =========================
# ğŸ’¬ ë‹µë³€ í•¨ìˆ˜
# =========================
def generate_answer(question: str) -> str:
    try:
        q_vec = embed_text(question)
        df = fetch_topk_chunks(q_vec, 5)
        if df.empty:
            return "ì£„ì†¡í•˜ì§€ë§Œ ê´€ë ¨ ì•½ê´€ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        context = "\n\n".join(df["text"].head(3))
        sys_prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë³´í—˜ ì•½ê´€ ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤.
        ì•„ë˜ ì•½ê´€ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê·¼ê±° ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

        [ì•½ê´€ ê´€ë ¨ ì¡°í•­]
        {context}
        """
        msgs = [SystemMessage(content=sys_prompt), HumanMessage(content=question)]
        resp = model.invoke(msgs)
        return resp.content
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# =========================
# ğŸ–¥ï¸ HTML UI
# =========================
chat_body_html = ''.join([
    f"<div class='{'user-bubble' if m['role']=='user' else 'bot-bubble'} bubble'>{m['content']}</div>"
    for m in st.session_state.messages
])

html_code = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script src="https://cdn.tailwindcss.com"></script>
<style>
body {{
  background-color: #f3f4f6;
  font-family: 'Pretendard', 'Inter', sans-serif;
  height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
}}
.chat-container {{
  width: 100%;
  max-width: 480px;
  height: 95vh;
  background: white;
  border-radius: 10px;
  box-shadow: 0 4px 12px rgba(0,0,0,0.1);
  display: flex;
  flex-direction: column;
  overflow: hidden;
}}
.chat-header {{
  background-color: #2563eb;
  color: white;
  padding: 16px;
}}
.chat-body {{
  flex: 1;
  overflow-y: auto;
  padding: 16px;
  background: white;
}}
.bubble {{
  padding: 10px 14px;
  border-radius: 20px;
  margin-bottom: 10px;
  max-width: 80%;
  line-height: 1.5;
  word-wrap: break-word;
}}
.user-bubble {{
  background-color: #2563eb;
  color: white;
  border-bottom-right-radius: 4px;
  margin-left: auto;
}}
.bot-bubble {{
  background-color: #e5e7eb;
  color: #111827;
  border-bottom-left-radius: 4px;
  margin-right: auto;
}}
.chat-input {{
  border-top: 1px solid #e5e7eb;
  padding: 12px;
  display: flex;
  gap: 8px;
  position: sticky;
  bottom: 0;
  background-color: white;
}}
.chat-input input {{
  flex: 1;
  padding: 10px 14px;
  border-radius: 999px;
  border: 1px solid #d1d5db;
  outline: none;
}}
.chat-input button {{
  background-color: #2563eb;
  color: white;
  border: none;
  border-radius: 50%;
  width: 44px;
  height: 44px;
  font-size: 1.2rem;
}}
</style>
</head>
<body>
<div class="chat-container">
  <div class="chat-header">
    <h1>ì•½ê´€ì±—ë´‡</h1>
    <p>NHLife | Made by íƒœí›ˆ,í˜„ì² </p>
  </div>
  <div class="chat-body">{chat_body_html}</div>

  <!-- âœ… ìˆ˜ì •ëœ ì…ë ¥ í¼ -->
  <form class="chat-input" method="get" action="">
    <input type="text" name="text" placeholder="ìƒí’ˆì— ëŒ€í•´ ê¶ê¸ˆí•œ ì  ì§ˆë¬¸í•´ì£¼ì„¸ìš”." autocomplete="off" required>
    <button type="submit">ğŸ“¤</button>
  </form>
</div>
</body>
</html>
"""


# =========================
# ğŸ“© ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬
# =========================
message = components.html(html_code, height=800, scrolling=False)
event = st.query_params.get("text")

if event:
    user_input = event
    st.session_state.messages.append({"role": "user", "content": user_input})
    answer = generate_answer(user_input)
    st.session_state.messages.append({"role": "assistant", "content": answer})
    st.rerun()
